{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0df5b15",
   "metadata": {},
   "source": [
    "# Quotes: From raw data to visualization\n",
    "\n",
    "This notebook will demo getting from the raw data to data that is ready to be visualized as point data and graph data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cbb78e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ba5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7eef3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'quotes_wisdom_7869'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a93fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We'll use the rootdir: djoin.rootdir='/Users/thorwhalen/.local/share/cosmo_notebooks/quotes_wisdom_7869'\n"
     ]
    }
   ],
   "source": [
    "rootdir = None\n",
    "\n",
    "if rootdir is None:\n",
    "    import config2py\n",
    "\n",
    "    rootdir = config2py.get_app_data_folder(\"cosmo_notebooks\")\n",
    "    rootdir = os.path.join(rootdir, data_name)\n",
    "    rootdir = config2py.process_path(rootdir, ensure_dir_exists=True)\n",
    "\n",
    "djoin = lambda *paths: os.path.join(rootdir, *paths)\n",
    "djoin.rootdir = rootdir  # to remember what we're using\n",
    "\n",
    "print(f\"We'll use the rootdir: {djoin.rootdir=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e51f0",
   "metadata": {},
   "source": [
    "## Get the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91452522",
   "metadata": {},
   "source": [
    "The raw data can be downloaded manuall from here: \n",
    "https://www.kaggle.com/datasets/beatafaron/wisdom-from-business-leaders-and-innovators\n",
    "\n",
    "If that's your way, you can skip the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b2797",
   "metadata": {},
   "source": [
    "### Get it with haggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0181c2f",
   "metadata": {},
   "source": [
    "#### Optional: Searching kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ef68cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>info.id</th>\n",
       "      <th>info.ref</th>\n",
       "      <th>info.subtitle</th>\n",
       "      <th>info.creatorName</th>\n",
       "      <th>info.creatorUrl</th>\n",
       "      <th>info.totalBytes</th>\n",
       "      <th>info.url</th>\n",
       "      <th>info.lastUpdated</th>\n",
       "      <th>info.downloadCount</th>\n",
       "      <th>...</th>\n",
       "      <th>info.description</th>\n",
       "      <th>info.ownerName</th>\n",
       "      <th>info.ownerRef</th>\n",
       "      <th>info.kernelCount</th>\n",
       "      <th>info.title</th>\n",
       "      <th>info.viewCount</th>\n",
       "      <th>info.voteCount</th>\n",
       "      <th>info.currentVersionNumber</th>\n",
       "      <th>info.usabilityRating</th>\n",
       "      <th>info.tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jsphyg/star-wars</td>\n",
       "      <td>239296</td>\n",
       "      <td>jsphyg/star-wars</td>\n",
       "      <td>Heroes, Starships, Planets, Weapons, and More,...</td>\n",
       "      <td>Joe Young</td>\n",
       "      <td>jsphyg</td>\n",
       "      <td>143878</td>\n",
       "      <td>https://www.kaggle.com/datasets/jsphyg/star-wars</td>\n",
       "      <td>2024-06-19T15:48:49.310Z</td>\n",
       "      <td>10450</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Joe Young</td>\n",
       "      <td>jsphyg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>The Star Wars Dataverse</td>\n",
       "      <td>68441</td>\n",
       "      <td>104.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>[{'ref': 'movies and tv shows', 'name': 'movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anilpaliwal/quotes-data-set</td>\n",
       "      <td>5140648</td>\n",
       "      <td>anilpaliwal/quotes-data-set</td>\n",
       "      <td>\"Exploring the Wisdom: An Analysis of Quotes ...</td>\n",
       "      <td>Anil Paliwal</td>\n",
       "      <td>anilpaliwal</td>\n",
       "      <td>5299</td>\n",
       "      <td>https://www.kaggle.com/datasets/anilpaliwal/qu...</td>\n",
       "      <td>2024-06-03T11:21:41.920Z</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Anil Paliwal</td>\n",
       "      <td>anilpaliwal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unveiling the Wisdom Within a Quotes Dataset</td>\n",
       "      <td>133</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>[{'ref': 'languages', 'name': 'languages', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brazzers/wisdom-quotes-70-quotes</td>\n",
       "      <td>1697012</td>\n",
       "      <td>brazzers/wisdom-quotes-70-quotes</td>\n",
       "      <td></td>\n",
       "      <td>Bezer</td>\n",
       "      <td>brazzers</td>\n",
       "      <td>5159</td>\n",
       "      <td>https://www.kaggle.com/datasets/brazzers/wisdo...</td>\n",
       "      <td>2021-11-05T15:06:48.923Z</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Bezer</td>\n",
       "      <td>brazzers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisdom Quotes - 70 quotes</td>\n",
       "      <td>1500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[{'ref': 'literature', 'name': 'literature', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>santhalnr/quotations</td>\n",
       "      <td>456845</td>\n",
       "      <td>santhalnr/quotations</td>\n",
       "      <td>4000 English quotations web scrapped</td>\n",
       "      <td>Santha Lakshmi Narayana</td>\n",
       "      <td>santhalnr</td>\n",
       "      <td>140694</td>\n",
       "      <td>https://www.kaggle.com/datasets/santhalnr/quot...</td>\n",
       "      <td>2019-12-26T13:36:38.050Z</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Santha Lakshmi Narayana</td>\n",
       "      <td>santhalnr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>English Quotations</td>\n",
       "      <td>4830</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>[{'ref': 'literature', 'name': 'literature', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thiru2905/quotes-dataset</td>\n",
       "      <td>8533365</td>\n",
       "      <td>thiru2905/quotes-dataset</td>\n",
       "      <td>A Dataset containing about Quotes and there au...</td>\n",
       "      <td>Thiru2905</td>\n",
       "      <td>thiru2905</td>\n",
       "      <td>7081</td>\n",
       "      <td>https://www.kaggle.com/datasets/thiru2905/quot...</td>\n",
       "      <td>2025-10-20T13:15:39.610Z</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Thiru2905</td>\n",
       "      <td>thiru2905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Quotes Dataset</td>\n",
       "      <td>38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'ref': 'categorical', 'name': 'categorical',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dwsstudio/scrapped-quotes</td>\n",
       "      <td>3811105</td>\n",
       "      <td>dwsstudio/scrapped-quotes</td>\n",
       "      <td>A collection of inspiring quotes from the Good...</td>\n",
       "      <td>Dakidarts</td>\n",
       "      <td>dwsstudio</td>\n",
       "      <td>516617</td>\n",
       "      <td>https://www.kaggle.com/datasets/dwsstudio/scra...</td>\n",
       "      <td>2023-10-03T23:40:00.187Z</td>\n",
       "      <td>181</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Dakidarts</td>\n",
       "      <td>dwsstudio</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Goodreads Quotes Dataset</td>\n",
       "      <td>937</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'ref': 'literature', 'name': 'literature', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tejasnisar/stoic-quotes</td>\n",
       "      <td>6702049</td>\n",
       "      <td>tejasnisar/stoic-quotes</td>\n",
       "      <td></td>\n",
       "      <td>Tejas Nisar</td>\n",
       "      <td>tejasnisar</td>\n",
       "      <td>97003</td>\n",
       "      <td>https://www.kaggle.com/datasets/tejasnisar/sto...</td>\n",
       "      <td>2025-02-19T22:16:52.483Z</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Tejas Nisar</td>\n",
       "      <td>tejasnisar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stoic quotes</td>\n",
       "      <td>402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>[{'ref': 'literature', 'name': 'literature', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beatafaron/wisdom-from-business-leaders-and-in...</td>\n",
       "      <td>7571817</td>\n",
       "      <td>beatafaron/wisdom-from-business-leaders-and-in...</td>\n",
       "      <td>Inspirational Quotes from Business Leaders and...</td>\n",
       "      <td>Beata Faron</td>\n",
       "      <td>beatafaron</td>\n",
       "      <td>791210</td>\n",
       "      <td>https://www.kaggle.com/datasets/beatafaron/wis...</td>\n",
       "      <td>2025-06-05T13:04:40.937Z</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Beata Faron</td>\n",
       "      <td>beatafaron</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wisdom from Business Leaders &amp; Innovators</td>\n",
       "      <td>319</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'ref': 'literature', 'name': 'literature', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>krishnatanwar/100inspirational-quotes-tags-and...</td>\n",
       "      <td>5652904</td>\n",
       "      <td>krishnatanwar/100inspirational-quotes-tags-and...</td>\n",
       "      <td>Inspiring Quotes Dataset with Author and Tag I...</td>\n",
       "      <td>Krishna Tanwar</td>\n",
       "      <td>krishnatanwar</td>\n",
       "      <td>7076</td>\n",
       "      <td>https://www.kaggle.com/datasets/krishnatanwar/...</td>\n",
       "      <td>2024-09-06T04:13:29.313Z</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Krishna Tanwar</td>\n",
       "      <td>krishnatanwar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100 Inspirational Quotes, Tags and Their Authors</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>[{'ref': 'literature', 'name': 'literature', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ref  info.id  \\\n",
       "0                                   jsphyg/star-wars   239296   \n",
       "1                        anilpaliwal/quotes-data-set  5140648   \n",
       "2                   brazzers/wisdom-quotes-70-quotes  1697012   \n",
       "3                               santhalnr/quotations   456845   \n",
       "4                           thiru2905/quotes-dataset  8533365   \n",
       "5                          dwsstudio/scrapped-quotes  3811105   \n",
       "6                            tejasnisar/stoic-quotes  6702049   \n",
       "7  beatafaron/wisdom-from-business-leaders-and-in...  7571817   \n",
       "8  krishnatanwar/100inspirational-quotes-tags-and...  5652904   \n",
       "\n",
       "                                            info.ref  \\\n",
       "0                                   jsphyg/star-wars   \n",
       "1                        anilpaliwal/quotes-data-set   \n",
       "2                   brazzers/wisdom-quotes-70-quotes   \n",
       "3                               santhalnr/quotations   \n",
       "4                           thiru2905/quotes-dataset   \n",
       "5                          dwsstudio/scrapped-quotes   \n",
       "6                            tejasnisar/stoic-quotes   \n",
       "7  beatafaron/wisdom-from-business-leaders-and-in...   \n",
       "8  krishnatanwar/100inspirational-quotes-tags-and...   \n",
       "\n",
       "                                       info.subtitle         info.creatorName  \\\n",
       "0  Heroes, Starships, Planets, Weapons, and More,...                Joe Young   \n",
       "1   \"Exploring the Wisdom: An Analysis of Quotes ...             Anil Paliwal   \n",
       "2                                                                       Bezer   \n",
       "3               4000 English quotations web scrapped  Santha Lakshmi Narayana   \n",
       "4  A Dataset containing about Quotes and there au...                Thiru2905   \n",
       "5  A collection of inspiring quotes from the Good...                Dakidarts   \n",
       "6                                                                 Tejas Nisar   \n",
       "7  Inspirational Quotes from Business Leaders and...              Beata Faron   \n",
       "8  Inspiring Quotes Dataset with Author and Tag I...           Krishna Tanwar   \n",
       "\n",
       "  info.creatorUrl  info.totalBytes  \\\n",
       "0          jsphyg           143878   \n",
       "1     anilpaliwal             5299   \n",
       "2        brazzers             5159   \n",
       "3       santhalnr           140694   \n",
       "4       thiru2905             7081   \n",
       "5       dwsstudio           516617   \n",
       "6      tejasnisar            97003   \n",
       "7      beatafaron           791210   \n",
       "8   krishnatanwar             7076   \n",
       "\n",
       "                                            info.url  \\\n",
       "0   https://www.kaggle.com/datasets/jsphyg/star-wars   \n",
       "1  https://www.kaggle.com/datasets/anilpaliwal/qu...   \n",
       "2  https://www.kaggle.com/datasets/brazzers/wisdo...   \n",
       "3  https://www.kaggle.com/datasets/santhalnr/quot...   \n",
       "4  https://www.kaggle.com/datasets/thiru2905/quot...   \n",
       "5  https://www.kaggle.com/datasets/dwsstudio/scra...   \n",
       "6  https://www.kaggle.com/datasets/tejasnisar/sto...   \n",
       "7  https://www.kaggle.com/datasets/beatafaron/wis...   \n",
       "8  https://www.kaggle.com/datasets/krishnatanwar/...   \n",
       "\n",
       "           info.lastUpdated  info.downloadCount  ... info.description  \\\n",
       "0  2024-06-19T15:48:49.310Z               10450  ...                    \n",
       "1  2024-06-03T11:21:41.920Z                  19  ...                    \n",
       "2  2021-11-05T15:06:48.923Z                  83  ...                    \n",
       "3  2019-12-26T13:36:38.050Z                 263  ...                    \n",
       "4  2025-10-20T13:15:39.610Z                   5  ...                    \n",
       "5  2023-10-03T23:40:00.187Z                 181  ...                    \n",
       "6  2025-02-19T22:16:52.483Z                  80  ...                    \n",
       "7  2025-06-05T13:04:40.937Z                  59  ...                    \n",
       "8  2024-09-06T04:13:29.313Z                  28  ...                    \n",
       "\n",
       "            info.ownerName  info.ownerRef info.kernelCount  \\\n",
       "0                Joe Young         jsphyg             10.0   \n",
       "1             Anil Paliwal    anilpaliwal              NaN   \n",
       "2                    Bezer       brazzers              NaN   \n",
       "3  Santha Lakshmi Narayana      santhalnr              1.0   \n",
       "4                Thiru2905      thiru2905              1.0   \n",
       "5                Dakidarts      dwsstudio              1.0   \n",
       "6              Tejas Nisar     tejasnisar              NaN   \n",
       "7              Beata Faron     beatafaron              2.0   \n",
       "8           Krishna Tanwar  krishnatanwar              NaN   \n",
       "\n",
       "                                         info.title info.viewCount  \\\n",
       "0                           The Star Wars Dataverse          68441   \n",
       "1      Unveiling the Wisdom Within a Quotes Dataset            133   \n",
       "2                        Wisdom Quotes - 70 quotes            1500   \n",
       "3                                English Quotations           4830   \n",
       "4                                    Quotes Dataset             38   \n",
       "5                          Goodreads Quotes Dataset            937   \n",
       "6                                      Stoic quotes            402   \n",
       "7         Wisdom from Business Leaders & Innovators            319   \n",
       "8  100 Inspirational Quotes, Tags and Their Authors            105   \n",
       "\n",
       "   info.voteCount  info.currentVersionNumber  info.usabilityRating  \\\n",
       "0           104.0                         12              0.941176   \n",
       "1             6.0                          1              0.882353   \n",
       "2             2.0                          1              0.250000   \n",
       "3            14.0                          1              0.875000   \n",
       "4             6.0                          1              1.000000   \n",
       "5             2.0                          1              1.000000   \n",
       "6             1.0                          1              0.764706   \n",
       "7             5.0                          4              1.000000   \n",
       "8             NaN                          1              0.647059   \n",
       "\n",
       "                                           info.tags  \n",
       "0  [{'ref': 'movies and tv shows', 'name': 'movie...  \n",
       "1  [{'ref': 'languages', 'name': 'languages', 'de...  \n",
       "2  [{'ref': 'literature', 'name': 'literature', '...  \n",
       "3  [{'ref': 'literature', 'name': 'literature', '...  \n",
       "4  [{'ref': 'categorical', 'name': 'categorical',...  \n",
       "5  [{'ref': 'literature', 'name': 'literature', '...  \n",
       "6  [{'ref': 'literature', 'name': 'literature', '...  \n",
       "7  [{'ref': 'literature', 'name': 'literature', '...  \n",
       "8  [{'ref': 'literature', 'name': 'literature', '...  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools, haggle, tabled, pandas as pd\n",
    "\n",
    "datasets_about_quotes = haggle.KaggleDatasetInfoReader(search='quotes wisdom')\n",
    "\n",
    "# make the results into a DataFrame for easy viewing\n",
    "options = pd.DataFrame(itertools.islice(datasets_about_quotes.items(), 10), columns=['ref', 'info'])\n",
    "options['info'] = options['info'].apply(lambda x: x.to_dict())\n",
    "options = tabled.expand_columns(options, 'info')\n",
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007301a",
   "metadata": {},
   "source": [
    "#### Get the data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06560d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quotes-wisdom.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the raw data (comes as a zip file)\n",
    "kaggle_ref = 'beatafaron/wisdom-from-business-leaders-and-innovators'\n",
    "\n",
    "h = haggle.KaggleDatasets()\n",
    "zip_store = h[kaggle_ref]\n",
    "list(zip_store)  # to see what's in the zip (and see what we should be taking as our data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d13a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(7869, 8)\n"
     ]
    }
   ],
   "source": [
    "# get the file we want from the zip and make a DataFrame out of it\n",
    "\n",
    "data_key = 'quotes-wisdom.csv'\n",
    "\n",
    "import io\n",
    "data = pd.read_csv(io.BytesIO(zip_store[data_key]))\n",
    "print(f\"{data.shape=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579168cf",
   "metadata": {},
   "source": [
    "### Peeping at the data\n",
    "\n",
    "This assumes you have the data in a DataFrame format at this point, whether you got it the way suggested above, or any other way. \n",
    "\n",
    "Here we'll just have a few peeps at the data (and maybe clean up a few values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95e8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(7869, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quote        It’s only after you’ve stepped outside your co...\n",
       "author                                          Roy T. Bennett\n",
       "theme/tag                                           leadership\n",
       "source                                  Goodreads – leadership\n",
       "position                                                Author\n",
       "region                                                 Unknown\n",
       "decade                                                   2010s\n",
       "gender                                                    male\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{data.shape=}\")\n",
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0663bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique quotes: 7869 (out of 7869 total rows)\n"
     ]
    }
   ],
   "source": [
    "t = data['quote'].nunique()\n",
    "print(f\"Number of unique quotes: {t} (out of {data.shape[0]} total rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db485d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male          6446\n",
       "Unknown        797\n",
       "female         618\n",
       "unknown          7\n",
       "non-binary       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e7d3191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male          6446\n",
       "unknown        804\n",
       "female         618\n",
       "non-binary       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing all gender strings with lowercase versions\n",
    "data['gender'] = data['gender'].str.lower()\n",
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee42358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theme/tag\n",
       "leadership    2207\n",
       "risk          1714\n",
       "success       1666\n",
       "failure       1461\n",
       "motivation     821\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['theme/tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d06ba977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['decade'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9c45dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Albert Einstein          561\n",
       "Martin Luther King Jr    459\n",
       "John F Kennedy           420\n",
       "Bertrand Russell         320\n",
       "Mahatma Gandhi           317\n",
       "                        ... \n",
       "Grace Hopper               1\n",
       "George Patton              1\n",
       "Orson Scott Card           1\n",
       "Leonardo da Vinci          1\n",
       "Claude Bissel              1\n",
       "Name: count, Length: 1029, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef8804",
   "metadata": {},
   "source": [
    "### Vectorize: Compute embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe288ea",
   "metadata": {},
   "source": [
    "To work with data (ML and all that Jazz), the first step is often to _vectorize_ the items of interest (here, segments). These vectors encode the _features_ of those items in some way. (For that reason, these vectors are often called _feature vectors_.) \n",
    "Now-a-days we talk a lot about (semantic) _embeddings_ when talking about feature vectors of text. It's just a different word, same thing though, with perhaps a bit more of a connotation of dimensionality reduction (e.g. OpenAI's embedding models reduce from a space of vectors (around) 8K (tokens of text) to one of 1.5K (text-embedding-ada-002) and 3K (text-embedding-3-large) numbers. \n",
    "\n",
    "Here, we'll compute embeddings with OpenAI models (which ever one is the default in the `oa` package (or the one you specify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b64ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: text-embedding-3-small\n",
      "Embeddings will be stored in: /Users/thorwhalen/.local/share/cosmo_notebooks/quotes_wisdom_7869/quotes_wisdom_7869__embeddings.parquet\n"
     ]
    }
   ],
   "source": [
    "import oa\n",
    "\n",
    "embedding_model = oa.DFLT_EMBEDDINGS_MODEL  # change if you want a different model\n",
    "\n",
    "# Where you want to store the embeddings file (to not have to recompute)\n",
    "embeddings_filepath = djoin(f'{data_name}__embeddings.parquet')\n",
    "\n",
    "print(f\"Using embedding model: {embedding_model}\")\n",
    "print(f\"Embeddings will be stored in: {embeddings_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813cbd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing embeddings from: /Users/thorwhalen/.local/share/cosmo_notebooks/quotes_wisdom_7869/quotes_wisdom_7869__embeddings.parquet\n",
      "Loaded 7869 embeddings.\n",
      "The embeddings are vectors of length 1536.\n"
     ]
    }
   ],
   "source": [
    "# Load existing embeddings or compute them\n",
    "\n",
    "if os.path.exists(embeddings_filepath):\n",
    "    print(f\"Loading existing embeddings from: {embeddings_filepath}\")\n",
    "    embeddings_df = pd.read_parquet(embeddings_filepath)\n",
    "    embeddings = embeddings_df['embedding'].tolist()\n",
    "    del embeddings_df  # just to offload them\n",
    "    print(f\"Loaded {len(embeddings)} embeddings.\")\n",
    "else:\n",
    "    import oa\n",
    "\n",
    "    print(f\"Computing embeddings for {data.shape[0]} quotes...\")\n",
    "    embeddings = oa.embeddings(data['quote'])\n",
    "    # Save the embeddings\n",
    "    embeddings_df = pd.DataFrame({'embedding': embeddings})\n",
    "    embeddings_df.to_parquet(embeddings_filepath)\n",
    "    del embeddings_df\n",
    "    print(f\"Saved embeddings to: {embeddings_filepath}\")\n",
    "    print(f\"Loaded {len(embeddings)} embeddings.\")\n",
    "\n",
    "print(f\"The embeddings are vectors of length {len(embeddings[0])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45aad83",
   "metadata": {},
   "source": [
    "### Planarize: Get planar coordinates for the embeddings\n",
    "\n",
    "In order to visualize the quotes, we'd like to transform the many-dimensional vectors to 2-dimensional vectors (planar coordinates).\n",
    "Basically, compute some other embeddings, that are here meant to produce a visual perspective of the similarity between items. \n",
    "\n",
    "All of these transformations will severely distort the actual distance between vectors, therefore the apparent similarity between the points (quotes here). \n",
    "Different transformations will lead to different distortions. \n",
    "We'll compute 2 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a5be096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe to hold the planar coordinates\n",
    "planar_coords_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c50c16",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "Principle Component Analysis is a classic one!\n",
    "When you use PCA to turn complex data into a simple 2D map, the two lines (axes) on that map are the best possible directions to look along because they show you where the biggest spread and differences (the maximum variance) were in the original, complicated data.\n",
    "Now, it's not always what you want (sometimes the maximum variance is noise). \n",
    "\n",
    "Still, it's nice because it's **very** fast, and scalable (even has some incremental learning abilities!). \n",
    "\n",
    "We could just do a \"normal\" PCA, but note we made a few parametrizations below. That's because we want to account for the unique geometry of semantic embedding spaces, which are built on direction (cosine similarity), not pure linear distance, and this requires L2 normalization to properly align the data's variance with its semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f95dbe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7869, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize # Use for L2 Normalization\n",
    "import numpy as np\n",
    "\n",
    "planar_coords_pca = PCA(\n",
    "    n_components=2,           # Reduces dimensionality to 2 for planar visualization.\n",
    "    whiten=False,             # Keeps the variance ratio of PC1/PC2 for better interpretation of spread.\n",
    ").fit_transform(\n",
    "    # L2 normalization aligns PCA's Euclidean distance with the semantic cosine similarity.\n",
    "    normalize(embeddings, axis=1, norm='l2') \n",
    ")\n",
    "\n",
    "# 3. Add coordinates to the DataFrame\n",
    "planar_coords_df['pca_x'] = planar_coords_pca[:, 0]\n",
    "planar_coords_df['pca_y'] = planar_coords_pca[:, 1]\n",
    "\n",
    "planar_coords_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419783d",
   "metadata": {},
   "source": [
    "#### TSNE\n",
    "\n",
    "t-SNE (t-distributed Stochastic Neighbor Embedding) is a non-linear dimensionality reduction technique that is often superior to PCA for visualization. It focuses on preserving the local structure of the high-dimensional data, meaning points that are close together in the original embedding space will remain close in the 2D map, often resulting in clear, separated clusters. However, unlike PCA, t-SNE is computationally expensive and sensitive to its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2da86c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7869, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize # Use for L2 Normalization (optional but safe)\n",
    "import numpy as np\n",
    "\n",
    "planar_coords_tsne = TSNE(\n",
    "    n_components=2,           # Reduces dimensionality to 2 for planar visualization.\n",
    "    metric='cosine',          # Crucial for semantic embeddings: ensures distance is based on vector angle (direction).\n",
    "    init='pca',               # Recommended: Uses PCA results for initialization, improving speed and stability.\n",
    "    random_state=42           # Ensures reproducibility.\n",
    ").fit_transform(\n",
    "    # Although t-SNE can calculate cosine distance internally, normalizing the input is often\n",
    "    # a cleaner approach, especially if comparing the input to L2-normalized vector stores.\n",
    "    normalize(embeddings, axis=1, norm='l2')\n",
    ")  # ~20s (Runtime depends heavily on dataset size)\n",
    "\n",
    "# 3. Add coordinates to the DataFrame\n",
    "planar_coords_df['tsne_x'] = planar_coords_tsne[:, 0]\n",
    "planar_coords_df['tsne_y'] = planar_coords_tsne[:, 1]\n",
    "\n",
    "# Check the final shape (should be (n_samples, 2))\n",
    "planar_coords_tsne.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f1790",
   "metadata": {},
   "source": [
    "#### Linear Dicriminant Analysis (LDA)\n",
    "\n",
    "While PCA and t-SNE are unsupervised techniques—meaning they project the data based purely on variance or local structure without knowing the categories—we can also use a supervised planarizer like LDA. Linear Discriminant Analysis (LDA) is specifically designed to find the axes (or \"linear discriminants\") that maximize the separation between known categories (classes) while minimizing the variance within those categories. This makes it ideal when the primary goal of your visualization is to clearly separate different semantic themes or tags in your embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57b2d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import normalize # Use for L2 Normalization\n",
    "import numpy as np\n",
    "X = np.array(embeddings)\n",
    "\n",
    "planar_coords_lda = LDA(\n",
    "    n_components=2           # Finds the 2 axes that best separate the class means.\n",
    ").fit_transform(\n",
    "    normalize(embeddings, axis=1, norm='l2'),  # The input feature vectors (embeddings)\n",
    "    data['theme/tag']                          # The required class labels/categories (supervision)\n",
    ")  # ~2s (LDA is generally quite fast)\n",
    "\n",
    "# 3. Add coordinates to the DataFrame\n",
    "planar_coords_df['lda_x'] = planar_coords_lda[:, 0]\n",
    "planar_coords_df['lda_y'] = planar_coords_lda[:, 1]\n",
    "\n",
    "# Check the final shape\n",
    "# planar_coords_lda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a3d72",
   "metadata": {},
   "source": [
    "#### The planar_coords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81748da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7869, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pca_x     -0.330981\n",
       "pca_y     -0.053535\n",
       "tsne_x   -53.058346\n",
       "tsne_y    -3.216958\n",
       "lda_x      1.315592\n",
       "lda_y     -1.366387\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{planar_coords_df.shape}\")\n",
    "planar_coords_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cec79",
   "metadata": {},
   "source": [
    "### Clusterize\n",
    "\n",
    "Here, we have enough categories to play with with our visualization, but we'd like to also get some idea of semantic categories that might emerge directly from the data. We can do some cluster analysis in the original embeddings space to be able to capture some semantic categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d845f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To hold the cluster indices\n",
    "cluster_indices_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b4c8d",
   "metadata": {},
   "source": [
    "#### Kmeans\n",
    "\n",
    "K-Means is the most widely used and arguably the simplest clustering algorithm. It is an unsupervised method that partitions data into $k$ predefined clusters by iteratively moving cluster centroids to the mean of the points assigned to them. It is exceptionally fast and highly scalable (a pro), even for very large datasets. However, K-Means suffers from two primary cons in the semantic embedding context: it requires you to pre-define the number of clusters ($\\text{n\\_clusters}$), and it fundamentally assumes clusters are spherical (or convex) and equally dense, which often fails to capture the complex, arbitrary shapes of semantic groups (as discussed previously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03ac9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=n_clusters,        # The number of clusters (k) must be chosen beforehand.\n",
    "    init='k-means++',     # Recommended initialization method for better results.\n",
    "    n_init='auto',        # Recommended: let sklearn automatically choose the best initialization run count.\n",
    "    random_state=42       # Ensures reproducibility of the initial centroid selection.\n",
    ").fit(\n",
    "    # This L2 Normalization step is CRUCIAL: it forces the Euclidean distance (used by K-Means) \n",
    "    # to be equivalent to the cosine distance, respecting the embedding's directional geometry.\n",
    "    normalize(embeddings, axis=1, norm='l2') \n",
    ")\n",
    "\n",
    "# 3. Add cluster IDs to the DataFrame\n",
    "cluster_indices_df[f'kmeans_clus_{n_clusters}'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4e767",
   "metadata": {},
   "source": [
    "#### Umap+HDBSCAN\n",
    "\n",
    "Both PCA and K-Means are limited by their assumptions (linearity and spherical clusters). The UMAP $\\rightarrow$ HDBSCAN pipeline is an **unsupervised** method designed to overcome these limitations.\n",
    "\n",
    "* **UMAP (Uniform Manifold Approximation and Projection)** is a **non-linear** dimensionality reduction technique that excels at finding and preserving the complex, curved **semantic manifold** where embeddings truly reside.\n",
    "* **HDBSCAN (Hierarchical DBSCAN)** is a **density-based** algorithm that automatically finds clusters of **arbitrary shapes** and sizes and labels noise points as $-1$.\n",
    "\n",
    "The combination is powerful because UMAP compresses the data into a low-dimensional space (e.g., 5D) where the semantic structure is clear, and HDBSCAN then finds the true, complex clusters within that compressed space. This yields higher quality, more semantically coherent clusters than K-Means, at the cost of significantly higher computational expense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13517688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thorwhalen/.pyenv/versions/p12/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/Users/thorwhalen/.pyenv/versions/p12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/thorwhalen/.pyenv/versions/p12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Takes about 10s\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import umap  # pip install umap-learn\n",
    "import hdbscan  # pip install hdbscan\n",
    "\n",
    "# Hyperparameters\n",
    "umap_n_components = 5         # UMAP intermediate dimension: 5 is a common sweet spot for clustering input.\n",
    "hdbscan_min_cluster_size = 10 # Key hyperparameter: minimum number of points required to form a cluster.\n",
    "\n",
    "# UMAP Reduction (to intermediate dimension)\n",
    "reducer = umap.UMAP(\n",
    "    n_components=umap_n_components, \n",
    "    metric='cosine',  # Tells UMAP to base neighbor distances on vector angles.\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ").fit(normalize(embeddings, axis=1, norm='l2') ) # Fit the reducer on the L2-normalized data\n",
    "\n",
    "# HDBSCAN Clustering (in the reduced UMAP space)\n",
    "# We cluster the UMAP output, not the original high-dimensional vectors.\n",
    "umap_hdbscan_labels = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=hdbscan_min_cluster_size, \n",
    ").fit_predict(reducer.embedding_) # reducer.embedding_ is the reduced data\n",
    "\n",
    "# Add cluster IDs to the DataFrame\n",
    "cluster_indices_df[f'umap_hdbscan_clus_{hdbscan_min_cluster_size}'] = umap_hdbscan_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c1ab9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_indices_df.shape=(7869, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "kmeans_clus_7            2\n",
       "umap_hdbscan_clus_10    84\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{cluster_indices_df.shape=}\")\n",
    "cluster_indices_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb0417",
   "metadata": {},
   "source": [
    "## Putting it all together, and visualizating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cbc5bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_with_coords_and_clusters.shape=(7869, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quote                   It’s only after you’ve stepped outside your co...\n",
       "author                                                     Roy T. Bennett\n",
       "theme/tag                                                      leadership\n",
       "source                                             Goodreads – leadership\n",
       "position                                                           Author\n",
       "region                                                            Unknown\n",
       "decade                                                              2010s\n",
       "gender                                                               male\n",
       "pca_x                                                           -0.330981\n",
       "pca_y                                                           -0.053535\n",
       "tsne_x                                                         -53.058346\n",
       "tsne_y                                                          -3.216958\n",
       "lda_x                                                            1.315592\n",
       "lda_y                                                           -1.366387\n",
       "kmeans_clus_7                                                           2\n",
       "umap_hdbscan_clus_10                                                   84\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add planar coords and cluster indices to the main data DataFrame\n",
    "data_with_coords_and_clusters = pd.concat(\n",
    "    [data, planar_coords_df, cluster_indices_df], axis=1\n",
    ")\n",
    "\n",
    "print(f\"{data_with_coords_and_clusters.shape=}\")\n",
    "data_with_coords_and_clusters.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea0c2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmograph import cosmo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9ea42ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c8bd790ae94909941c1e217ba07ef3",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Cosmograph(background_color=None, components_display_state_mode=None, focused_point_ring_color=None, hovered_p…"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo(\n",
    "    data_with_coords_and_clusters,\n",
    "    point_label_by='quote',\n",
    "    point_x_by='tsne_x',  # e.g. pca_x, tsne_x, lda_x\n",
    "    point_y_by='tsne_y',  # e.g. pca_y, tsne_y, lda_y\n",
    "    point_color_by='theme/tag'  # e.g. 'theme/tag', 'kmeans_clus_7', 'umap_hdbscan_clus_10'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "985bfd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c7e93a8b90491cae2fa0b16801a223",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Cosmograph(background_color=None, components_display_state_mode=None, focused_point_ring_color=None, hovered_p…"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo(\n",
    "    data_with_coords_and_clusters,\n",
    "    point_label_by='quote',\n",
    "    point_x_by='lda_x',  # e.g. pca_x, tsne_x, lda_x\n",
    "    point_y_by='lda_y',  # e.g. pca_y, tsne_y, lda_y\n",
    "    point_color_by='theme/tag'  # e.g. 'theme/tag', 'kmeans_clus_7', 'umap_hdbscan_clus_10'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b0ec933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>theme/tag</th>\n",
       "      <th>source</th>\n",
       "      <th>position</th>\n",
       "      <th>region</th>\n",
       "      <th>decade</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It’s only after you’ve stepped outside your co...</td>\n",
       "      <td>Roy T. Bennett</td>\n",
       "      <td>leadership</td>\n",
       "      <td>Goodreads – leadership</td>\n",
       "      <td>Author</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2010s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Success is not how high you have climbed, but ...</td>\n",
       "      <td>Roy T. Bennett</td>\n",
       "      <td>leadership</td>\n",
       "      <td>Goodreads – leadership</td>\n",
       "      <td>Author</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2010s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Be grateful for what you already have while yo...</td>\n",
       "      <td>Roy T. Bennett</td>\n",
       "      <td>leadership</td>\n",
       "      <td>Goodreads – leadership</td>\n",
       "      <td>Author</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2010s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is a curious thing, Harry, but perhaps thos...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>leadership</td>\n",
       "      <td>Goodreads – leadership</td>\n",
       "      <td>Author</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2000s</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You never change your life until you step out ...</td>\n",
       "      <td>Roy T. Bennett</td>\n",
       "      <td>leadership</td>\n",
       "      <td>Goodreads – leadership</td>\n",
       "      <td>Author</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2010s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>The secret to winning is learning how to lose....</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>success</td>\n",
       "      <td>WisdomQuotes – resilience</td>\n",
       "      <td>Author</td>\n",
       "      <td>North America</td>\n",
       "      <td>2020s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>Rowing harder doesn’t help if the boat is head...</td>\n",
       "      <td>Kenichi Ohmae</td>\n",
       "      <td>failure</td>\n",
       "      <td>WisdomQuotes – resilience</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>The most resilient people are like playful, cu...</td>\n",
       "      <td>Al Siebert</td>\n",
       "      <td>risk</td>\n",
       "      <td>WisdomQuotes – resilience</td>\n",
       "      <td>Psychologist</td>\n",
       "      <td>North America</td>\n",
       "      <td>2000s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>Risk more than others think is safe. Care more...</td>\n",
       "      <td>Claude Bissel</td>\n",
       "      <td>risk</td>\n",
       "      <td>WisdomQuotes – resilience</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>Never bet against someone who won’t quit</td>\n",
       "      <td>Jack Butcher</td>\n",
       "      <td>success</td>\n",
       "      <td>WisdomQuotes – resilience</td>\n",
       "      <td>Designer</td>\n",
       "      <td>North America</td>\n",
       "      <td>2020s</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7869 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  quote          author  \\\n",
       "0     It’s only after you’ve stepped outside your co...  Roy T. Bennett   \n",
       "1     Success is not how high you have climbed, but ...  Roy T. Bennett   \n",
       "2     Be grateful for what you already have while yo...  Roy T. Bennett   \n",
       "3     It is a curious thing, Harry, but perhaps thos...    J.K. Rowling   \n",
       "4     You never change your life until you step out ...  Roy T. Bennett   \n",
       "...                                                 ...             ...   \n",
       "7864  The secret to winning is learning how to lose....     James Clear   \n",
       "7865  Rowing harder doesn’t help if the boat is head...   Kenichi Ohmae   \n",
       "7866  The most resilient people are like playful, cu...      Al Siebert   \n",
       "7867  Risk more than others think is safe. Care more...   Claude Bissel   \n",
       "7868           Never bet against someone who won’t quit    Jack Butcher   \n",
       "\n",
       "       theme/tag                     source      position         region  \\\n",
       "0     leadership     Goodreads – leadership        Author        Unknown   \n",
       "1     leadership     Goodreads – leadership        Author        Unknown   \n",
       "2     leadership     Goodreads – leadership        Author        Unknown   \n",
       "3     leadership     Goodreads – leadership        Author         Europe   \n",
       "4     leadership     Goodreads – leadership        Author        Unknown   \n",
       "...          ...                        ...           ...            ...   \n",
       "7864     success  WisdomQuotes – resilience        Author  North America   \n",
       "7865     failure  WisdomQuotes – resilience       Unknown        Unknown   \n",
       "7866        risk  WisdomQuotes – resilience  Psychologist  North America   \n",
       "7867        risk  WisdomQuotes – resilience       Unknown        Unknown   \n",
       "7868     success  WisdomQuotes – resilience      Designer  North America   \n",
       "\n",
       "       decade   gender  \n",
       "0       2010s     male  \n",
       "1       2010s     male  \n",
       "2       2010s     male  \n",
       "3       2000s   female  \n",
       "4       2010s     male  \n",
       "...       ...      ...  \n",
       "7864    2020s     male  \n",
       "7865  Unknown  unknown  \n",
       "7866    2000s     male  \n",
       "7867  Unknown  unknown  \n",
       "7868    2020s     male  \n",
       "\n",
       "[7869 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6920a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in data['quote'] if x.lower().startswith('attributed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b6ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
